{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mnist_cnn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"3FQPhwdy-ZY3","colab_type":"text"},"cell_type":"markdown","source":["# Keras implementation for training CNN with kaggle MNIST dataset"]},{"metadata":{"id":"wzErP_IPHadl","colab_type":"code","outputId":"4067dad8-185b-4003-8d90-b2ae7f9ec452","executionInfo":{"status":"ok","timestamp":1542844924186,"user_tz":300,"elapsed":60768,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"cell_type":"code","source":["#mount driver with data\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"metadata":{"id":"eANUg15IHinU","colab_type":"code","colab":{}},"cell_type":"code","source":["#read data\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import os\n","\n","train_set = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/MNIST_CNN/data/train.csv\")\n","test_set = pd.read_csv(\"/content/gdrive/My Drive/Colab Notebooks/MNIST_CNN/data/test.csv\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6fRNfcdPI7W8","colab_type":"code","outputId":"5d84cd77-49fe-43bc-c8ed-71549e7f42ca","executionInfo":{"status":"ok","timestamp":1542844958580,"user_tz":300,"elapsed":95114,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":392}},"cell_type":"code","source":["train_set.head(10)"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>pixel0</th>\n","      <th>pixel1</th>\n","      <th>pixel2</th>\n","      <th>pixel3</th>\n","      <th>pixel4</th>\n","      <th>pixel5</th>\n","      <th>pixel6</th>\n","      <th>pixel7</th>\n","      <th>pixel8</th>\n","      <th>...</th>\n","      <th>pixel774</th>\n","      <th>pixel775</th>\n","      <th>pixel776</th>\n","      <th>pixel777</th>\n","      <th>pixel778</th>\n","      <th>pixel779</th>\n","      <th>pixel780</th>\n","      <th>pixel781</th>\n","      <th>pixel782</th>\n","      <th>pixel783</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>...</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10 rows × 785 columns</p>\n","</div>"],"text/plain":["   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n","0      1       0       0       0       0       0       0       0       0   \n","1      0       0       0       0       0       0       0       0       0   \n","2      1       0       0       0       0       0       0       0       0   \n","3      4       0       0       0       0       0       0       0       0   \n","4      0       0       0       0       0       0       0       0       0   \n","5      0       0       0       0       0       0       0       0       0   \n","6      7       0       0       0       0       0       0       0       0   \n","7      3       0       0       0       0       0       0       0       0   \n","8      5       0       0       0       0       0       0       0       0   \n","9      3       0       0       0       0       0       0       0       0   \n","\n","   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n","0       0    ...            0         0         0         0         0   \n","1       0    ...            0         0         0         0         0   \n","2       0    ...            0         0         0         0         0   \n","3       0    ...            0         0         0         0         0   \n","4       0    ...            0         0         0         0         0   \n","5       0    ...            0         0         0         0         0   \n","6       0    ...            0         0         0         0         0   \n","7       0    ...            0         0         0         0         0   \n","8       0    ...            0         0         0         0         0   \n","9       0    ...            0         0         0         0         0   \n","\n","   pixel779  pixel780  pixel781  pixel782  pixel783  \n","0         0         0         0         0         0  \n","1         0         0         0         0         0  \n","2         0         0         0         0         0  \n","3         0         0         0         0         0  \n","4         0         0         0         0         0  \n","5         0         0         0         0         0  \n","6         0         0         0         0         0  \n","7         0         0         0         0         0  \n","8         0         0         0         0         0  \n","9         0         0         0         0         0  \n","\n","[10 rows x 785 columns]"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"ThJxudODJAr_","colab_type":"code","outputId":"8ffe6e4e-021e-448f-a1ba-7d1ce1bb75bf","executionInfo":{"status":"ok","timestamp":1542844960929,"user_tz":300,"elapsed":97444,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["#normalize and seperate labels from train/test set\n","labels = train_set.pop('label')\n","features = train_set.values / 255.0\n","test_features = test_set.values / 255.0\n","features = features.astype('float32')\n","test_features = test_features.astype('float32')\n","features = features.reshape(features.shape[0],28,28,1)\n","test_features = test_features.reshape(test_features.shape[0],28,28,1)\n","print(features.shape)\n","print(labels.shape)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["(42000, 28, 28, 1)\n","(42000,)\n"],"name":"stdout"}]},{"metadata":{"id":"TAdD9cyNJoVQ","colab_type":"code","outputId":"9d54e095-1eec-46c1-e6f6-e06aded79da1","executionInfo":{"status":"ok","timestamp":1542844960930,"user_tz":300,"elapsed":97426,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":202}},"cell_type":"code","source":["#checking labels\n","print(labels[0:10])"],"execution_count":5,"outputs":[{"output_type":"stream","text":["0    1\n","1    0\n","2    1\n","3    4\n","4    0\n","5    0\n","6    7\n","7    3\n","8    5\n","9    3\n","Name: label, dtype: int64\n"],"name":"stdout"}]},{"metadata":{"id":"Y8EuCkX8J4pg","colab_type":"code","colab":{}},"cell_type":"code","source":["#use get_dummies for one-hot encoding and convert to numpy array\n","labels = pd.get_dummies(labels)\n","labels = labels.values"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1Pq-VrVBKCEN","colab_type":"code","outputId":"e44bd39c-8c68-4390-cc6b-a2332d72d6f7","executionInfo":{"status":"ok","timestamp":1542844961019,"user_tz":300,"elapsed":97477,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":185}},"cell_type":"code","source":["print(labels[0:10])"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[[0 1 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0]\n"," [0 1 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 1 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0]\n"," [1 0 0 0 0 0 0 0 0 0]\n"," [0 0 0 0 0 0 0 1 0 0]\n"," [0 0 0 1 0 0 0 0 0 0]\n"," [0 0 0 0 0 1 0 0 0 0]\n"," [0 0 0 1 0 0 0 0 0 0]]\n"],"name":"stdout"}]},{"metadata":{"id":"Kn-bKF9kKJcc","colab_type":"code","outputId":"12c68435-122e-41af-fe70-912bf4bbe5d3","executionInfo":{"status":"ok","timestamp":1542844965368,"user_tz":300,"elapsed":101815,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#create model\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout,Flatten, Activation\n","from keras.layers.convolutional import Conv2D, MaxPooling2D\n","from keras.layers.advanced_activations import LeakyReLU\n","from keras.layers.normalization import BatchNormalization\n","\n","model = Sequential()\n","model.add(Conv2D(40, kernel_size=5, padding=\"same\",input_shape=(28, 28, 1)))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Conv2D(70, kernel_size=3, padding=\"same\"))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Conv2D(500, kernel_size=3, padding=\"same\"))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n","model.add(Conv2D(1024, kernel_size=3, padding=\"valid\"))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","\n","#Flatten and use fully-connected layers to output labels\n","model.add(Flatten())\n","model.add(Dense(units=100))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","model.add(Dropout(0.1))\n","model.add(Dense(units=100))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","model.add(Dropout(0.1))\n","model.add(Dense(units=100))\n","model.add(BatchNormalization())\n","model.add(LeakyReLU())\n","model.add(Dropout(0.3))\n","model.add(Dense(10))\n","model.add(Activation(\"softmax\"))\n","\n","#compile model\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"8OY9JYKZLI3J","colab_type":"code","outputId":"a4fdcbc1-1769-4267-fd94-7813c1019127","executionInfo":{"status":"ok","timestamp":1542857658697,"user_tz":300,"elapsed":9492304,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":5477}},"cell_type":"code","source":["from sklearn.model_selection import KFold\n","from keras.preprocessing.image import ImageDataGenerator\n","kf = KFold(n_splits=5,shuffle=True)\n","for train_index, test_index in kf.split(features,labels):\n","  X_train, y_train = features[train_index], labels[train_index]\n","  X_test, y_test = features[test_index], labels[test_index]\n","  model.fit(X_train,y_train,epochs=32,shuffle=True,verbose=1,validation_data=(X_test, y_test))"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Train on 33600 samples, validate on 8400 samples\n","Epoch 1/32\n","33600/33600 [==============================] - 92s 3ms/step - loss: 0.0307 - acc: 0.9910 - val_loss: 0.0193 - val_acc: 0.9945\n","Epoch 2/32\n","33600/33600 [==============================] - 86s 3ms/step - loss: 0.0207 - acc: 0.9938 - val_loss: 0.0162 - val_acc: 0.9958\n","Epoch 3/32\n","33600/33600 [==============================] - 85s 3ms/step - loss: 0.0167 - acc: 0.9953 - val_loss: 0.0200 - val_acc: 0.9948\n","Epoch 4/32\n","33600/33600 [==============================] - 87s 3ms/step - loss: 0.0137 - acc: 0.9956 - val_loss: 0.0244 - val_acc: 0.9937\n","Epoch 5/32\n","33600/33600 [==============================] - 87s 3ms/step - loss: 0.0126 - acc: 0.9962 - val_loss: 0.0300 - val_acc: 0.9913\n","Epoch 6/32\n","33600/33600 [==============================] - 90s 3ms/step - loss: 0.0106 - acc: 0.9965 - val_loss: 0.0295 - val_acc: 0.9924\n","Epoch 7/32\n","33600/33600 [==============================] - 90s 3ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0220 - val_acc: 0.9945\n","Epoch 8/32\n","33600/33600 [==============================] - 89s 3ms/step - loss: 0.0092 - acc: 0.9971 - val_loss: 0.0252 - val_acc: 0.9925\n","Epoch 9/32\n","33600/33600 [==============================] - 82s 2ms/step - loss: 0.0098 - acc: 0.9972 - val_loss: 0.0264 - val_acc: 0.9932\n","Epoch 10/32\n","33600/33600 [==============================] - 81s 2ms/step - loss: 0.0080 - acc: 0.9976 - val_loss: 0.0268 - val_acc: 0.9933\n","Epoch 11/32\n","33600/33600 [==============================] - 81s 2ms/step - loss: 0.0078 - acc: 0.9974 - val_loss: 0.0219 - val_acc: 0.9942\n","Epoch 12/32\n","33600/33600 [==============================] - 83s 2ms/step - loss: 0.0074 - acc: 0.9978 - val_loss: 0.0262 - val_acc: 0.9936\n","Epoch 13/32\n","33600/33600 [==============================] - 82s 2ms/step - loss: 0.0064 - acc: 0.9977 - val_loss: 0.0243 - val_acc: 0.9931\n","Epoch 14/32\n","33600/33600 [==============================] - 82s 2ms/step - loss: 0.0061 - acc: 0.9982 - val_loss: 0.0216 - val_acc: 0.9938\n","Epoch 15/32\n","33600/33600 [==============================] - 83s 2ms/step - loss: 0.0069 - acc: 0.9979 - val_loss: 0.0394 - val_acc: 0.9901\n","Epoch 16/32\n","33600/33600 [==============================] - 86s 3ms/step - loss: 0.0056 - acc: 0.9983 - val_loss: 0.0288 - val_acc: 0.9931\n","Epoch 17/32\n","33600/33600 [==============================] - 89s 3ms/step - loss: 0.0048 - acc: 0.9983 - val_loss: 0.0258 - val_acc: 0.9937\n","Epoch 18/32\n","33600/33600 [==============================] - 94s 3ms/step - loss: 0.0060 - acc: 0.9982 - val_loss: 0.0309 - val_acc: 0.9930\n","Epoch 19/32\n","33600/33600 [==============================] - 98s 3ms/step - loss: 0.0051 - acc: 0.9985 - val_loss: 0.0246 - val_acc: 0.9945\n","Epoch 20/32\n","33600/33600 [==============================] - 100s 3ms/step - loss: 0.0048 - acc: 0.9984 - val_loss: 0.0230 - val_acc: 0.9944\n","Epoch 21/32\n","33600/33600 [==============================] - 100s 3ms/step - loss: 0.0046 - acc: 0.9987 - val_loss: 0.0361 - val_acc: 0.9925\n","Epoch 22/32\n","33600/33600 [==============================] - 89s 3ms/step - loss: 0.0061 - acc: 0.9983 - val_loss: 0.0286 - val_acc: 0.9936\n","Epoch 23/32\n","33600/33600 [==============================] - 80s 2ms/step - loss: 0.0053 - acc: 0.9985 - val_loss: 0.0260 - val_acc: 0.9932\n","Epoch 24/32\n","33600/33600 [==============================] - 76s 2ms/step - loss: 0.0039 - acc: 0.9986 - val_loss: 0.0405 - val_acc: 0.9913\n","Epoch 25/32\n","33600/33600 [==============================] - 77s 2ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0375 - val_acc: 0.9921\n","Epoch 26/32\n","33600/33600 [==============================] - 77s 2ms/step - loss: 0.0036 - acc: 0.9989 - val_loss: 0.0275 - val_acc: 0.9929\n","Epoch 27/32\n","33600/33600 [==============================] - 77s 2ms/step - loss: 0.0031 - acc: 0.9990 - val_loss: 0.0260 - val_acc: 0.9939\n","Epoch 28/32\n","33600/33600 [==============================] - 78s 2ms/step - loss: 0.0039 - acc: 0.9988 - val_loss: 0.0427 - val_acc: 0.9889\n","Epoch 29/32\n","33600/33600 [==============================] - 79s 2ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0230 - val_acc: 0.9940\n","Epoch 30/32\n","33600/33600 [==============================] - 80s 2ms/step - loss: 0.0025 - acc: 0.9993 - val_loss: 0.0724 - val_acc: 0.9821\n","Epoch 31/32\n","33600/33600 [==============================] - 82s 2ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0262 - val_acc: 0.9948\n","Epoch 32/32\n","33600/33600 [==============================] - 72s 2ms/step - loss: 0.0050 - acc: 0.9985 - val_loss: 0.0232 - val_acc: 0.9944\n","Train on 33600 samples, validate on 8400 samples\n","Epoch 1/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0130 - acc: 0.9965 - val_loss: 0.0037 - val_acc: 0.9987\n","Epoch 2/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0078 - acc: 0.9977 - val_loss: 0.0033 - val_acc: 0.9987\n","Epoch 3/32\n","33600/33600 [==============================] - 57s 2ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0052 - val_acc: 0.9981\n","Epoch 4/32\n","33600/33600 [==============================] - 64s 2ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0024 - val_acc: 0.9990\n","Epoch 5/32\n","33600/33600 [==============================] - 63s 2ms/step - loss: 0.0052 - acc: 0.9985 - val_loss: 0.0046 - val_acc: 0.9982\n","Epoch 6/32\n","33600/33600 [==============================] - 71s 2ms/step - loss: 0.0034 - acc: 0.9990 - val_loss: 0.0020 - val_acc: 0.9992\n","Epoch 7/32\n","33600/33600 [==============================] - 58s 2ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0024 - val_acc: 0.9994\n","Epoch 8/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0046 - acc: 0.9986 - val_loss: 0.0108 - val_acc: 0.9965\n","Epoch 9/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0041 - acc: 0.9989 - val_loss: 0.0041 - val_acc: 0.9982\n","Epoch 10/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0023 - val_acc: 0.9994\n","Epoch 11/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0100 - val_acc: 0.9963\n","Epoch 12/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0044 - val_acc: 0.9987\n","Epoch 13/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0035 - acc: 0.9992 - val_loss: 0.0050 - val_acc: 0.9986\n","Epoch 14/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0031 - acc: 0.9991 - val_loss: 0.0062 - val_acc: 0.9979\n","Epoch 15/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0032 - acc: 0.9992 - val_loss: 0.0061 - val_acc: 0.9983\n","Epoch 16/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0138 - val_acc: 0.9956\n","Epoch 17/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 0.0042 - val_acc: 0.9988\n","Epoch 18/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0053 - acc: 0.9989 - val_loss: 0.0183 - val_acc: 0.9950\n","Epoch 19/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0065 - val_acc: 0.9981\n","Epoch 20/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0151 - val_acc: 0.9952\n","Epoch 21/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0029 - acc: 0.9993 - val_loss: 0.0121 - val_acc: 0.9970\n","Epoch 22/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0032 - acc: 0.9991 - val_loss: 0.0076 - val_acc: 0.9977\n","Epoch 23/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9985\n","Epoch 24/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0048 - acc: 0.9987 - val_loss: 0.0089 - val_acc: 0.9977\n","Epoch 25/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 0.0086 - val_acc: 0.9979\n","Epoch 26/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0012 - acc: 0.9999 - val_loss: 0.0060 - val_acc: 0.9987\n","Epoch 27/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0042 - acc: 0.9988 - val_loss: 0.0102 - val_acc: 0.9974\n","Epoch 28/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0040 - acc: 0.9989 - val_loss: 0.0071 - val_acc: 0.9981\n","Epoch 29/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0037 - acc: 0.9990 - val_loss: 0.0072 - val_acc: 0.9983\n","Epoch 30/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0139 - val_acc: 0.9960\n","Epoch 31/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0095 - val_acc: 0.9976\n","Epoch 32/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0083 - val_acc: 0.9981\n","Train on 33600 samples, validate on 8400 samples\n","Epoch 1/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0096 - acc: 0.9972 - val_loss: 6.1869e-04 - val_acc: 0.9999\n","Epoch 2/32\n","33600/33600 [==============================] - 50s 2ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0013 - val_acc: 0.9995\n","Epoch 3/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 9.2312e-05 - val_acc: 1.0000\n","Epoch 4/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0016 - acc: 0.9996 - val_loss: 1.0148e-04 - val_acc: 1.0000\n","Epoch 5/32\n","33600/33600 [==============================] - 54s 2ms/step - loss: 0.0030 - acc: 0.9990 - val_loss: 0.0015 - val_acc: 0.9996\n","Epoch 6/32\n","33600/33600 [==============================] - 58s 2ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0012 - val_acc: 0.9998\n","Epoch 7/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0026 - acc: 0.9994 - val_loss: 0.0015 - val_acc: 0.9994\n","Epoch 8/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0033 - acc: 0.9991 - val_loss: 7.2527e-04 - val_acc: 0.9998\n","Epoch 9/32\n","33600/33600 [==============================] - 63s 2ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0020 - val_acc: 0.9995\n","Epoch 10/32\n","33600/33600 [==============================] - 67s 2ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 2.2329e-04 - val_acc: 1.0000\n","Epoch 11/32\n","33600/33600 [==============================] - 69s 2ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 3.7269e-04 - val_acc: 0.9999\n","Epoch 12/32\n","33600/33600 [==============================] - 67s 2ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 1.8591e-04 - val_acc: 1.0000\n","Epoch 13/32\n","33600/33600 [==============================] - 61s 2ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0016 - val_acc: 0.9993\n","Epoch 14/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 0.0028 - val_acc: 0.9990\n","Epoch 15/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0027 - acc: 0.9993 - val_loss: 0.0016 - val_acc: 0.9996\n","Epoch 16/32\n","33600/33600 [==============================] - 50s 2ms/step - loss: 0.0025 - acc: 0.9995 - val_loss: 0.0015 - val_acc: 0.9993\n","Epoch 17/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0010 - acc: 0.9999 - val_loss: 7.4731e-04 - val_acc: 0.9998\n","Epoch 18/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 0.0041 - val_acc: 0.9987\n","Epoch 19/32\n","33600/33600 [==============================] - 55s 2ms/step - loss: 0.0030 - acc: 0.9992 - val_loss: 9.3923e-04 - val_acc: 0.9996\n","Epoch 20/32\n","33600/33600 [==============================] - 54s 2ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.0031 - val_acc: 0.9994\n","Epoch 21/32\n","33600/33600 [==============================] - 61s 2ms/step - loss: 0.0022 - acc: 0.9995 - val_loss: 4.3753e-04 - val_acc: 0.9999\n","Epoch 22/32\n","33600/33600 [==============================] - 67s 2ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 7.4271e-04 - val_acc: 0.9996\n","Epoch 23/32\n","33600/33600 [==============================] - 76s 2ms/step - loss: 0.0031 - acc: 0.9993 - val_loss: 0.0038 - val_acc: 0.9988\n","Epoch 24/32\n","33600/33600 [==============================] - 75s 2ms/step - loss: 0.0023 - acc: 0.9996 - val_loss: 0.0026 - val_acc: 0.9989\n","Epoch 25/32\n","33600/33600 [==============================] - 64s 2ms/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0026 - val_acc: 0.9994\n","Epoch 26/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0028 - acc: 0.9993 - val_loss: 0.0013 - val_acc: 0.9995\n","Epoch 27/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 9.3575e-04 - val_acc: 0.9994\n","Epoch 28/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0032 - acc: 0.9994 - val_loss: 0.0017 - val_acc: 0.9994\n","Epoch 29/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0035 - acc: 0.9990 - val_loss: 0.0033 - val_acc: 0.9988\n","Epoch 30/32\n","33600/33600 [==============================] - 52s 2ms/step - loss: 0.0028 - acc: 0.9992 - val_loss: 0.0029 - val_acc: 0.9989\n","Epoch 31/32\n","33600/33600 [==============================] - 52s 2ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0035 - val_acc: 0.9990\n","Epoch 32/32\n","33600/33600 [==============================] - 52s 2ms/step - loss: 9.0906e-04 - acc: 0.9999 - val_loss: 0.0026 - val_acc: 0.9994\n","Train on 33600 samples, validate on 8400 samples\n","Epoch 1/32\n","33600/33600 [==============================] - 52s 2ms/step - loss: 0.0040 - acc: 0.9988 - val_loss: 1.0579e-04 - val_acc: 1.0000\n","Epoch 2/32\n","33600/33600 [==============================] - 52s 2ms/step - loss: 0.0036 - acc: 0.9991 - val_loss: 4.9148e-04 - val_acc: 0.9998\n","Epoch 3/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 3.8175e-04 - val_acc: 0.9999\n","Epoch 4/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0018 - acc: 0.9997 - val_loss: 1.8332e-04 - val_acc: 0.9999\n","Epoch 5/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 6.1749e-05 - val_acc: 1.0000\n","Epoch 6/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 1.2261e-04 - val_acc: 1.0000\n","Epoch 7/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0036 - acc: 0.9990 - val_loss: 8.2162e-04 - val_acc: 0.9998\n","Epoch 8/32\n","33600/33600 [==============================] - 53s 2ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0017 - val_acc: 0.9994\n","Epoch 9/32\n","33600/33600 [==============================] - 64s 2ms/step - loss: 0.0030 - acc: 0.9993 - val_loss: 0.0011 - val_acc: 0.9998\n","Epoch 10/32\n","33600/33600 [==============================] - 61s 2ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0017 - val_acc: 0.9995\n","Epoch 11/32\n","33600/33600 [==============================] - 61s 2ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0016 - val_acc: 0.9998\n","Epoch 12/32\n","33600/33600 [==============================] - 61s 2ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 1.8050e-04 - val_acc: 1.0000\n","Epoch 13/32\n","33600/33600 [==============================] - 61s 2ms/step - loss: 0.0024 - acc: 0.9994 - val_loss: 0.0012 - val_acc: 0.9996\n","Epoch 14/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0021 - acc: 0.9996 - val_loss: 6.8898e-04 - val_acc: 0.9998\n","Epoch 15/32\n","33600/33600 [==============================] - 64s 2ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 4.6751e-04 - val_acc: 0.9998\n","Epoch 16/32\n","33600/33600 [==============================] - 54s 2ms/step - loss: 0.0025 - acc: 0.9994 - val_loss: 7.0557e-04 - val_acc: 0.9996\n","Epoch 17/32\n","33600/33600 [==============================] - 58s 2ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 1.6154e-04 - val_acc: 1.0000\n","Epoch 18/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0018 - acc: 0.9996 - val_loss: 2.6382e-04 - val_acc: 0.9999\n","Epoch 19/32\n","33600/33600 [==============================] - 62s 2ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 3.3301e-04 - val_acc: 1.0000\n","Epoch 20/32\n","33600/33600 [==============================] - 66s 2ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 5.4383e-04 - val_acc: 0.9998\n","Epoch 21/32\n","33600/33600 [==============================] - 66s 2ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 4.5496e-04 - val_acc: 0.9998\n","Epoch 22/32\n","33600/33600 [==============================] - 62s 2ms/step - loss: 0.0016 - acc: 0.9995 - val_loss: 5.8884e-04 - val_acc: 0.9998\n","Epoch 23/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0014 - acc: 0.9996 - val_loss: 9.9627e-04 - val_acc: 0.9998\n","Epoch 24/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 5.1580e-04 - val_acc: 0.9996\n","Epoch 25/32\n","33600/33600 [==============================] - 52s 2ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0019 - val_acc: 0.9995\n","Epoch 26/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0012 - val_acc: 0.9999\n","Epoch 27/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0010 - val_acc: 0.9999\n","Epoch 28/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 8.3477e-04 - acc: 0.9998 - val_loss: 0.0012 - val_acc: 0.9996\n","Epoch 29/32\n","33600/33600 [==============================] - 50s 1ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 6.8593e-04 - val_acc: 0.9998\n","Epoch 30/32\n","33600/33600 [==============================] - 53s 2ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0011 - val_acc: 0.9996\n","Epoch 31/32\n","33600/33600 [==============================] - 59s 2ms/step - loss: 0.0027 - acc: 0.9992 - val_loss: 8.2923e-04 - val_acc: 0.9998\n","Epoch 32/32\n","33600/33600 [==============================] - 58s 2ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0010 - val_acc: 0.9998\n","Train on 33600 samples, validate on 8400 samples\n","Epoch 1/32\n","33600/33600 [==============================] - 57s 2ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 1.9532e-05 - val_acc: 1.0000\n","Epoch 2/32\n","33600/33600 [==============================] - 51s 2ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 8.2161e-05 - val_acc: 1.0000\n","Epoch 3/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0012 - val_acc: 0.9995\n","Epoch 4/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0033 - acc: 0.9992 - val_loss: 6.3698e-05 - val_acc: 1.0000\n","Epoch 5/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0013 - acc: 0.9996 - val_loss: 1.0471e-04 - val_acc: 1.0000\n","Epoch 6/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0019 - acc: 0.9994 - val_loss: 9.3154e-04 - val_acc: 0.9995\n","Epoch 7/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 2.6265e-04 - val_acc: 1.0000\n","Epoch 8/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0017 - acc: 0.9996 - val_loss: 2.2279e-04 - val_acc: 1.0000\n","Epoch 9/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0014 - acc: 0.9998 - val_loss: 4.1210e-04 - val_acc: 0.9998\n","Epoch 10/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0011 - acc: 0.9998 - val_loss: 2.4899e-05 - val_acc: 1.0000\n","Epoch 11/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0035 - acc: 0.9993 - val_loss: 8.0877e-04 - val_acc: 0.9998\n","Epoch 12/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 9.0762e-04 - acc: 0.9998 - val_loss: 1.3142e-04 - val_acc: 1.0000\n","Epoch 13/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0026 - acc: 0.9993 - val_loss: 1.7940e-04 - val_acc: 0.9999\n","Epoch 14/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 9.6294e-04 - acc: 0.9998 - val_loss: 8.3667e-05 - val_acc: 1.0000\n","Epoch 15/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0013 - acc: 0.9998 - val_loss: 5.0391e-04 - val_acc: 0.9998\n","Epoch 16/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0028 - acc: 0.9994 - val_loss: 0.0020 - val_acc: 0.9990\n","Epoch 17/32\n","33600/33600 [==============================] - 48s 1ms/step - loss: 0.0020 - acc: 0.9996 - val_loss: 7.5834e-04 - val_acc: 0.9998\n","Epoch 18/32\n","33600/33600 [==============================] - 49s 1ms/step - loss: 0.0010 - acc: 0.9998 - val_loss: 4.7292e-04 - val_acc: 0.9998\n","Epoch 19/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0021 - acc: 0.9994 - val_loss: 1.4937e-04 - val_acc: 1.0000\n","Epoch 20/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 8.7414e-04 - acc: 0.9999 - val_loss: 6.4168e-04 - val_acc: 0.9998\n","Epoch 21/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 5.8601e-04 - acc: 0.9999 - val_loss: 1.5553e-04 - val_acc: 1.0000\n","Epoch 22/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0030 - val_acc: 0.9992\n","Epoch 23/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0032 - acc: 0.9993 - val_loss: 0.0010 - val_acc: 0.9998\n","Epoch 24/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 3.0269e-04 - val_acc: 1.0000\n","Epoch 25/32\n","33600/33600 [==============================] - 46s 1ms/step - loss: 0.0015 - acc: 0.9998 - val_loss: 2.3852e-04 - val_acc: 0.9999\n","Epoch 26/32\n","33600/33600 [==============================] - 46s 1ms/step - loss: 6.4113e-04 - acc: 0.9999 - val_loss: 1.0456e-04 - val_acc: 1.0000\n","Epoch 27/32\n","33600/33600 [==============================] - 46s 1ms/step - loss: 0.0018 - acc: 0.9995 - val_loss: 5.8457e-04 - val_acc: 0.9998\n","Epoch 28/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 5.6531e-04 - acc: 1.0000 - val_loss: 4.7293e-04 - val_acc: 0.9999\n","Epoch 29/32\n","33600/33600 [==============================] - 46s 1ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0036 - val_acc: 0.9990\n","Epoch 30/32\n","33600/33600 [==============================] - 46s 1ms/step - loss: 0.0012 - acc: 0.9998 - val_loss: 7.6384e-04 - val_acc: 0.9999\n","Epoch 31/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0023 - acc: 0.9994 - val_loss: 0.0040 - val_acc: 0.9985\n","Epoch 32/32\n","33600/33600 [==============================] - 47s 1ms/step - loss: 0.0025 - acc: 0.9996 - val_loss: 0.0011 - val_acc: 0.9995\n"],"name":"stdout"}]},{"metadata":{"id":"n7nxBIUyF7vo","colab_type":"code","colab":{}},"cell_type":"code","source":["#save model\n","model.save(\"/content/gdrive/My Drive/Colab Notebooks/MNIST_CNN/model/model1.h5\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bgYXnegMIhIm","colab_type":"code","outputId":"d0d455de-30fd-4270-9fff-df2c4f3db8af","executionInfo":{"status":"ok","timestamp":1542858291502,"user_tz":300,"elapsed":6275,"user":{"displayName":"Sangwu Lee","photoUrl":"","userId":"08959789800233677789"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["#predict labels\n","predicted_labels = model.predict_classes(test_features)\n","print(predicted_labels)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["[2 0 9 ... 3 9 2]\n"],"name":"stdout"}]},{"metadata":{"id":"oxvPzwIFJLSe","colab_type":"code","colab":{}},"cell_type":"code","source":["#make a submit csv file for kaggle submission\n","submit = pd.DataFrame({\"ImageId\" : range(1,len(predicted_labels) + 1),\n","                       \"Label\" : predicted_labels})\n","submit.to_csv(\"/content/gdrive/My Drive/Colab Notebooks/MNIST_CNN/submit.csv\", index = False)"],"execution_count":0,"outputs":[]}]}